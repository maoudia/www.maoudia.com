[{"objectID":"https://www.maoudia.com/categories/reactive%20programming","title":"Reactive programming","type":"category","url":"https://www.maoudia.com/categories/reactive%20programming"},{"objectID":"https://www.maoudia.com/categories/tutorial","title":"Tutorial","type":"category","url":"https://www.maoudia.com/categories/tutorial"},{"objectID":"https://www.maoudia.com/author/moncef-aoudia","title":"Moncef AOUDIA","type":"author","url":"https://www.maoudia.com/author/moncef-aoudia"},{"objectID":"https://www.maoudia.com/tags/best%20practices","title":"Best practices","type":"tag","url":"https://www.maoudia.com/tags/best%20practices"},{"objectID":"https://www.maoudia.com/tags/configuration","title":"Configuration","type":"tag","url":"https://www.maoudia.com/tags/configuration"},{"objectID":"https://www.maoudia.com/tags/docker%20compose","title":"Docker compose","type":"tag","url":"https://www.maoudia.com/tags/docker%20compose"},{"objectID":"https://www.maoudia.com/tags/eip","title":"Eip","type":"tag","url":"https://www.maoudia.com/tags/eip"},{"objectID":"https://www.maoudia.com/tags/error%20handling","title":"Error handling","type":"tag","url":"https://www.maoudia.com/tags/error%20handling"},{"objectID":"https://www.maoudia.com/tags/file%20system","title":"File system","type":"tag","url":"https://www.maoudia.com/tags/file%20system"},{"objectID":"https://www.maoudia.com/tags/java","title":"Java","type":"tag","url":"https://www.maoudia.com/tags/java"},{"objectID":"https://www.maoudia.com/tags/logback","title":"Logback","type":"tag","url":"https://www.maoudia.com/tags/logback"},{"objectID":"https://www.maoudia.com/tags/logging","title":"Logging","type":"tag","url":"https://www.maoudia.com/tags/logging"},{"objectID":"https://www.maoudia.com/tags/mongodb","title":"Mongodb","type":"tag","url":"https://www.maoudia.com/tags/mongodb"},{"objectID":"https://www.maoudia.com/tags/performance","title":"Performance","type":"tag","url":"https://www.maoudia.com/tags/performance"},{"objectID":"https://www.maoudia.com/tags/project%20reactor","title":"Project reactor","type":"tag","url":"https://www.maoudia.com/tags/project%20reactor"},{"objectID":"https://www.maoudia.com/tags/reactive%20programming","title":"Reactive programming","type":"tag","url":"https://www.maoudia.com/tags/reactive%20programming"},{"objectID":"https://www.maoudia.com/tags/reactor","title":"Reactor","type":"tag","url":"https://www.maoudia.com/tags/reactor"},{"objectID":"https://www.maoudia.com/tags/resource%20management","title":"Resource management","type":"tag","url":"https://www.maoudia.com/tags/resource%20management"},{"objectID":"https://www.maoudia.com/tags/spring%20boot","title":"Spring boot","type":"tag","url":"https://www.maoudia.com/tags/spring%20boot"},{"objectID":"https://www.maoudia.com/tags/spring%20data","title":"Spring data","type":"tag","url":"https://www.maoudia.com/tags/spring%20data"},{"objectID":"https://www.maoudia.com/tags/spring%20webflux","title":"Spring webflux","type":"tag","url":"https://www.maoudia.com/tags/spring%20webflux"},{"objectID":"https://www.maoudia.com/tags/testcontainers","title":"Testcontainers","type":"tag","url":"https://www.maoudia.com/tags/testcontainers"},{"objectID":"https://www.maoudia.com/tags/visualvm","title":"Visualvm","type":"tag","url":"https://www.maoudia.com/tags/visualvm"},{"objectID":"https://www.maoudia.com/series/mongodb%20reactive%20cli","title":"Mongodb reactive CLI","type":"series","url":"https://www.maoudia.com/series/mongodb%20reactive%20cli"},{"author":"Moncef AOUDIA","categories":["Tutorial","Reactive Programming"],"content":" Reactor Disposable provides a mechanism for managing resources, subscriptions, or actions in a reactive application. This guide explores three main types: Disposable, Disposable.Composite, and Disposable.Swap, with practical examples using Spring Boot. Table of contents 1. Overview 2. Types of Disposables 3. Project Setup 4. Domain Model 5. Implementation 6. Testing 7. Use Cases and Best Practices 8. Common Patterns 9. Troubleshooting 10. Performance Considerations 11. Conclusion 12. Resources 1. Overview In reactive programming, proper resource management is crucial to prevent memory leaks and ensure clean shutdown of applications. Project Reactor provides the Disposable interface and its variants to manage the lifecycle of reactive streams and associated resources. This tutorial demonstrates practical usage of these disposables in a Spring Boot application with a user search service that manages asynchronous operations. 2. Types of Disposables 2.1. Disposable Represents a single resource that can be disposed of when it’s no longer needed, typically used for cleanup purposes. Failed to generate image: mmdc failed: Error: Failed to launch the browser process! [1202/155045.409969:FATAL:zygote_host_impl_linux.cc(128)] No usable sandbox! If you are running on Ubuntu 23.10+ or another Linux distro that has disabled unprivileged user namespaces with AppArmor, see https://chromium.googlesource.com/chromium/src/+/main/docs/security/apparmor-userns-restrictions.md. Otherwise see https://chromium.googlesource.com/chromium/src/+/main/docs/linux/suid_sandbox_development.md for more information on developing with the (older) SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox. TROUBLESHOOTING: https://pptr.dev/troubleshooting at Interface.onClose (file:///home/runner/work/www.maoudia.com/www.maoudia.com/node_modules/@puppeteer/browsers/lib/esm/launch.js:303:24) at Interface.emit (node:events:539:35) at Interface.close (node:readline:586:8) at Socket.onend (node:readline:277:10) at Socket.emit (node:events:539:35) at endReadableNT (node:internal/streams/readable:1345:12) at processTicksAndRejections (node:internal/process/task_queues:83:21) %%{init: {\u0026#39;theme\u0026#39;:\u0026#39;neutral\u0026#39;, \u0026#39;themeVariables\u0026#39;: { \u0026#39;fontSize\u0026#39;:\u0026#39;18px\u0026#39;}}}%% graph LR A[\u0026#34;\u0026lt;b\u0026gt;Disposable\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt;Single Resource Management\u0026#34;] --\u0026gt; B[Create Subscription] B --\u0026gt; C[Active ✓] C --\u0026gt; D[dispose] D --\u0026gt; E[Released ❌] classDef typeStyle fill:#2563eb,stroke:#1e40af,color:#fff,stroke-width:3px classDef activeStyle fill:#10b981,stroke:#059669,color:#fff,stroke-width:2px classDef disposedStyle fill:#ef4444,stroke:#dc2626,color:#fff,stroke-width:2px classDef neutralStyle fill:#f3f4f6,stroke:#9ca3af,color:#111,stroke-width:2px class A typeStyle class C activeStyle class E disposedStyle class B,D neutralStyle 2.1.1. Real-World Usage Messaging Application: Manage subscriptions to message queues. When a user subscribes to a topic, create a disposable subscription. When they unsubscribe, call dispose() to release resources. File Processing System: Manage file streams. When a file is opened for processing, create a disposable stream. When processing completes or an error occurs, dispose the stream to release system resources. 2.1.2. Example Disposable subscription = flux .subscribe( value -\u0026gt; System.out.println(value), error -\u0026gt; System.err.println(error), () -\u0026gt; System.out.println(\u0026#34;Complete\u0026#34;) ); subscription.dispose(); 2.2. Disposable.Composite Represents a collection of disposables that can be managed as a single unit, allowing for the disposal of multiple resources at once. Failed to generate image: mmdc failed: Error: Failed to launch the browser process! [1202/155046.085627:FATAL:zygote_host_impl_linux.cc(128)] No usable sandbox! If you are running on Ubuntu 23.10+ or another Linux distro that has disabled unprivileged user namespaces with AppArmor, see https://chromium.googlesource.com/chromium/src/+/main/docs/security/apparmor-userns-restrictions.md. Otherwise see https://chromium.googlesource.com/chromium/src/+/main/docs/linux/suid_sandbox_development.md for more information on developing with the (older) SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox. TROUBLESHOOTING: https://pptr.dev/troubleshooting at Interface.onClose (file:///home/runner/work/www.maoudia.com/www.maoudia.com/node_modules/@puppeteer/browsers/lib/esm/launch.js:303:24) at Interface.emit (node:events:539:35) at Interface.close (node:readline:586:8) at Socket.onend (node:readline:277:10) at Socket.emit (node:events:539:35) at endReadableNT (node:internal/streams/readable:1345:12) at processTicksAndRejections (node:internal/process/task_queues:83:21) %%{init: {\u0026#39;theme\u0026#39;:\u0026#39;neutral\u0026#39;, \u0026#39;themeVariables\u0026#39;: { \u0026#39;fontSize\u0026#39;:\u0026#39;18px\u0026#39;}}}%% graph TB A[\u0026#34;\u0026lt;b\u0026gt;Disposable.Composite\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt;Multiple Resources Management\u0026#34;] A --\u0026gt; B[Subscription 1 ✓] A --\u0026gt; C[Subscription 2 ✓] A --\u0026gt; D[Subscription 3 ✓] B --\u0026gt; E[dispose all] C --\u0026gt; E D --\u0026gt; E E --\u0026gt; F[All Released ❌] classDef typeStyle fill:#7B68EE,stroke:#5C4DB8,color:#fff,stroke-width:3px classDef activeStyle fill:#10b981,stroke:#059669,color:#fff,stroke-width:2px classDef disposedStyle fill:#ef4444,stroke:#dc2626,color:#fff,stroke-width:2px classDef neutralStyle fill:#f3f4f6,stroke:#9ca3af,color:#111,stroke-width:2px class A typeStyle class B,C,D activeStyle class F disposedStyle class E neutralStyle 2.2.1. Real-World Usage Financial Trading Application: Manage multiple subscriptions to market data feeds, trade execution services, and risk management systems. Dispose of all subscriptions together when the trading system shuts down. IoT System: Manage multiple sensor readings or device connections. Dispose of all connections together when the IoT device is turned off or removed from the network. 2.2.2. Example Disposable.Composite composite = Disposables.composite(); composite.add(subscription1); composite.add(subscription2); composite.add(subscription3); composite.dispose(); 2.3. Disposable.Swap Allows for the dynamic replacement of one disposable with another, enabling seamless transitions between different resources or actions. Failed to generate image: mmdc failed: Error: Failed to launch the browser process! [1202/155046.562711:FATAL:zygote_host_impl_linux.cc(128)] No usable sandbox! If you are running on Ubuntu 23.10+ or another Linux distro that has disabled unprivileged user namespaces with AppArmor, see https://chromium.googlesource.com/chromium/src/+/main/docs/security/apparmor-userns-restrictions.md. Otherwise see https://chromium.googlesource.com/chromium/src/+/main/docs/linux/suid_sandbox_development.md for more information on developing with the (older) SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox. TROUBLESHOOTING: https://pptr.dev/troubleshooting at Interface.onClose (file:///home/runner/work/www.maoudia.com/www.maoudia.com/node_modules/@puppeteer/browsers/lib/esm/launch.js:303:24) at Interface.emit (node:events:539:35) at Interface.close (node:readline:586:8) at Socket.onend (node:readline:277:10) at Socket.emit (node:events:539:35) at endReadableNT (node:internal/streams/readable:1345:12) at processTicksAndRejections (node:internal/process/task_queues:83:21) %%{init: {\u0026#39;theme\u0026#39;:\u0026#39;neutral\u0026#39;, \u0026#39;themeVariables\u0026#39;: { \u0026#39;fontSize\u0026#39;:\u0026#39;18px\u0026#39;}}}%% graph LR A[\u0026#34;\u0026lt;b\u0026gt;Disposable.Swap\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt;Dynamic Replacement\u0026#34;] --\u0026gt; B[Subscription 1 ✓] B --\u0026gt; C[update] C --\u0026gt; D[Sub 1: Disposed ❌] C --\u0026gt; E[Subscription 2 ✓] E --\u0026gt; F[update] F --\u0026gt; G[Sub 2: Disposed ❌] F --\u0026gt; H[Subscription 3 ✓] classDef typeStyle fill:#50C878,stroke:#3AA05E,color:#fff,stroke-width:3px classDef activeStyle fill:#10b981,stroke:#059669,color:#fff,stroke-width:2px classDef disposedStyle fill:#ef4444,stroke:#dc2626,color:#fff,stroke-width:2px classDef neutralStyle fill:#f3f4f6,stroke:#9ca3af,color:#111,stroke-width:2px class A typeStyle class B,E,H activeStyle class D,G disposedStyle class C,F neutralStyle 2.3.1. Real-World Usage Chat Application: Manage connections to chat servers. When a user switches chat rooms, replace the current connection with a new one using Disposable.Swap, enabling seamless room transitions. Gaming Server: Manage player sessions. When a player logs in or joins a game, create a disposable session. Replace sessions smoothly as players move between games. 2.3.2. Disposable.Swap vs switchMap Aspect switchMap Disposable.Swap Control Automatic switching Manual control Cancellation Handled automatically Requires explicit handling Use Case Stream transformation Resource management Complexity Simpler for stream operations More control for resources switchMap: Automatically switches between Publishers, discarding previous ones, without user intervention for cancellation handling. Disposable.Swap: Allows manual cancellation handling for seamless replacement of disposables, providing more control over resource lifecycle. 3. Project Setup 3.1. Requirements OpenJDK 21.0.x Maven 3.9.x Spring Boot 3.2.x 3.2. Maven Configuration pom.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.maoudia\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;app\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;maoudia-app\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;MAOUDIA APP\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;21\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;21\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-webflux\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.projectreactor\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;reactor-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 4. Domain Model 4.1. User Record User.java 1 2 3 4 5 6 7 package com.maoudia; public record User( String username, String firstName, String lastName, int age) {} 4.2. UserRepository Interface UserRepository.java 1 2 3 4 5 6 7 8 package com.maoudia; import reactor.core.publisher.Flux; public interface UserRepository { Flux\u0026lt;User\u0026gt; searchByUsername(String username); } 5. Implementation 5.1. Fake Repository Implementation This implementation simulates a real repository with random latency to demonstrate async behavior: FakeUserRepository.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package com.maoudia; import org.springframework.stereotype.Component; import reactor.core.publisher.Flux; import reactor.core.scheduler.Schedulers; import java.time.Duration; import java.util.Arrays; import java.util.List; import java.util.Random; @Component public class FakeUserRepository implements UserRepository { private static final Random random = new Random(); @Override public Flux\u0026lt;User\u0026gt; searchByUsername(String username) { (1) List\u0026lt;User\u0026gt; users = Arrays.asList( new User(\u0026#34;user1\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;, 30), new User(\u0026#34;user2\u0026#34;, \u0026#34;Jane\u0026#34;, \u0026#34;Smith\u0026#34;, 25), new User(\u0026#34;user3\u0026#34;, \u0026#34;Alice\u0026#34;, \u0026#34;Johnson\u0026#34;, 35), new User(\u0026#34;user4\u0026#34;, \u0026#34;Michael\u0026#34;, \u0026#34;Brown\u0026#34;, 40), new User(\u0026#34;user5\u0026#34;, \u0026#34;Emma\u0026#34;, \u0026#34;Wilson\u0026#34;, 28) ); return Flux.fromIterable(users) .filter(user -\u0026gt; user.username().startsWith(username)) (2) .delayElements(Duration.ofMillis(random.nextInt(1000) + 1), Schedulers.boundedElastic()); (3) } } 1 Searches for users by username, returning a reactive stream. 2 Filters users whose usernames start with the provided search term. 3 Introduces random latency (up to 1 second) to simulate real-world async operations. 5.2. UserService with Disposable.Swap This service demonstrates the usage of Disposable.Swap for managing user search operations: UserService.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package com.maoudia; import jakarta.annotation.PreDestroy; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Service; import reactor.core.Disposable; import reactor.core.Disposables; import reactor.core.scheduler.Schedulers; import java.util.UUID; @Service public class UserService { private static final Logger LOGGER = LoggerFactory.getLogger(UserService.class); private final UserRepository userRepository; private final Disposable.Swap disposableSwap; (1) public UserService(UserRepository userRepository) { this.userRepository = userRepository; this.disposableSwap = Disposables.swap(); (2) } public Disposable searchUsers(String query) { (3) Disposable nextDisposable = this.userRepository.searchByUsername(query) .doOnCancel(() -\u0026gt; LOGGER.warn(\u0026#34;User search for \u0026#39;{}\u0026#39; cancelled\u0026#34;, query)) (4) .doOnSubscribe(s -\u0026gt; LOGGER.info(\u0026#34;User search for \u0026#39;{}\u0026#39; subscribed: {}\u0026#34;, query, UUID.randomUUID())) (5) .subscribeOn(Schedulers.boundedElastic()) (6) .subscribe( user -\u0026gt; LOGGER.info(\u0026#34;User search \u0026#39;{}\u0026#39; found: {}\u0026#34;, query, user.username()), error -\u0026gt; LOGGER.error(\u0026#34;Error during User search for \u0026#39;{}\u0026#39;\u0026#34;, query, error), () -\u0026gt; LOGGER.info(\u0026#34;User search for \u0026#39;{}\u0026#39; completed\u0026#34;, query) ); disposableSwap.update(nextDisposable); (7) return disposableSwap; } @PreDestroy (8) public void cleanUp() { if (!this.disposableSwap.isDisposed()) { this.disposableSwap.dispose(); LOGGER.info(\u0026#34;Disposed of disposableSwap\u0026#34;); } } } 1 Declares a Disposable.Swap instance to manage search operations. 2 Initializes the swap container in the constructor. 3 Performs asynchronous user search and returns the disposable. 4 Logs when a search operation is cancelled. 5 Logs when a search operation is subscribed with a unique ID. 6 Executes the search on the bounded elastic scheduler for blocking operations. 7 Atomically replaces the previous disposable with the new one, disposing the old one. 8 Ensures proper cleanup when the service bean is destroyed. 5.3. How Disposable.Swap Works When searchUsers() is called multiple times: First call creates a disposable for \u0026#34;user1\u0026#34; search Second call creates a disposable for \u0026#34;user3\u0026#34; search and automatically disposes the \u0026#34;user1\u0026#34; search Third call creates a disposable for \u0026#34;user\u0026#34; search and automatically disposes the \u0026#34;user3\u0026#34; search Only the most recent search remains active. Previous searches are cancelled automatically. 6. Testing 6.1. Single Search Test UserServiceTest.java (excerpt) 1 2 3 4 5 6 7 8 9 @Test @DisplayName(\u0026#34;Single search for users by username\u0026#34;) void singleSearchUsersByUsername() { Disposable disposable = userService.searchUsers(\u0026#34;user1\u0026#34;); Assertions.assertThat(disposable) .isNotNull() .isInstanceOf(Disposable.Swap.class); } 6.2. Multiple Searches Test This test demonstrates how Disposable.Swap automatically disposes previous searches: UserServiceTest.java (excerpt) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Test @DisplayName(\u0026#34;Multiple searches for users by username\u0026#34;) void multipleSearchUsersByUsername() { Disposable disposable1 = userService.searchUsers(\u0026#34;user5\u0026#34;); (1) Disposable.Swap disposableSwap1 = (Disposable.Swap) disposable1; disposable1 = disposableSwap1.get(); (2) Disposable disposable2 = userService.searchUsers(\u0026#34;user3\u0026#34;); (3) Disposable.Swap disposableSwap2 = (Disposable.Swap) disposable2; disposable2 = disposableSwap2.get(); Disposable disposable3 = userService.searchUsers(\u0026#34;user\u0026#34;); (4) Assertions.assertThat(disposable1.isDisposed()).isTrue(); (5) Assertions.assertThat(disposable2.isDisposed()).isTrue(); Assertions.assertThat(disposable3) .isNotNull() .isInstanceOf(Disposable.Swap.class); } 1 First search for \u0026#34;user5\u0026#34; - creates disposable1. 2 Extract the inner disposable from the swap container. 3 Second search for \u0026#34;user3\u0026#34; - creates disposable2 and disposes disposable1. 4 Third search for \u0026#34;user\u0026#34; - creates disposable3 and disposes disposable2. 5 Verify that previous disposables are disposed, only the last one remains active. 6.3. Cleanup Test UserServiceTest.java (excerpt) 1 2 3 4 5 6 7 8 9 @Test @DisplayName(\u0026#34;Clean up resources\u0026#34;) void cleanUpResources() { Disposable disposable = userService.searchUsers(\u0026#34;user1\u0026#34;); userService.cleanUp(); Assertions.assertThat(disposable.isDisposed()).isTrue(); } 7. Use Cases and Best Practices 7.1. When to Use Each Type 7.1.1. Use Disposable When Managing a single subscription or resource Simple cleanup scenarios One-time operations Disposable subscription = flux.subscribe(); subscription.dispose(); 7.1.2. Use Disposable.Composite When Managing multiple independent subscriptions Grouping related resources Bulk cleanup operations Disposable.Composite composite = Disposables.composite( subscription1, subscription2, subscription3 ); composite.dispose(); 7.1.3. Use Disposable.Swap When Replacing active subscriptions dynamically Search-as-you-type scenarios Real-time data switching Session management Disposable.Swap swap = Disposables.swap(); swap.update(newSubscription); 7.2. Best Practices 7.2.1. Always Clean Up Resources Use @PreDestroy or implement DisposableBean to ensure cleanup: @PreDestroy public void cleanUp() { if (!disposable.isDisposed()) { disposable.dispose(); } } 7.2.2. Check Disposal Status Before disposing, check if already disposed to avoid errors: if (!disposable.isDisposed()) { disposable.dispose(); } 7.2.3. Use Appropriate Schedulers Choose schedulers based on operation type: .subscribeOn(Schedulers.boundedElastic()) .publishOn(Schedulers.parallel()) 7.2.4. Add Logging Include logging for debugging and monitoring: .doOnSubscribe(s -\u0026gt; log.info(\u0026#34;Subscribed\u0026#34;)) .doOnCancel(() -\u0026gt; log.warn(\u0026#34;Cancelled\u0026#34;)) .doOnComplete(() -\u0026gt; log.info(\u0026#34;Completed\u0026#34;)) 7.2.5. Handle Errors Gracefully Always provide error handlers: .subscribe( value -\u0026gt; process(value), error -\u0026gt; log.error(\u0026#34;Error\u0026#34;, error), () -\u0026gt; log.info(\u0026#34;Complete\u0026#34;) ) 8. Common Patterns 8.1. Search-as-You-Type Perfect use case for Disposable.Swap: public class SearchService { private final Disposable.Swap searchSwap = Disposables.swap(); public void search(String query) { Disposable search = repository.search(query) .subscribe(result -\u0026gt; display(result)); searchSwap.update(search); } } 8.2. Multi-Resource Management Use Disposable.Composite for managing multiple resources: public class DataService { private final Disposable.Composite subscriptions = Disposables.composite(); public void start() { subscriptions.add(dataFeed1.subscribe()); subscriptions.add(dataFeed2.subscribe()); subscriptions.add(dataFeed3.subscribe()); } @PreDestroy public void stop() { subscriptions.dispose(); } } 8.3. Session Management Replace sessions dynamically with Disposable.Swap: public class SessionManager { private final Disposable.Swap sessionSwap = Disposables.swap(); public void switchSession(String sessionId) { Disposable session = sessionService.connect(sessionId) .subscribe(); sessionSwap.update(session); } } 9. Troubleshooting 9.1. Memory Leaks If you notice memory leaks: Ensure all disposables are disposed in @PreDestroy methods Check for forgotten subscriptions Use memory profilers to identify leaked subscriptions 9.2. Race Conditions When using Disposable.Swap: The update() method is thread-safe and atomic Previous disposable is disposed before the new one is set No manual synchronization needed 9.3. Disposed Too Early If operations are cancelled unexpectedly: Check if parent component is being destroyed Verify disposal isn’t called prematurely Add logging to track disposal lifecycle 10. Performance Considerations 10.1. Thread Pools Use Schedulers.boundedElastic() for blocking operations (I/O, database) Use Schedulers.parallel() for CPU-intensive operations Avoid creating custom schedulers unnecessarily 10.2. Memory Overhead Disposable.Swap has minimal memory overhead (single reference) Disposable.Composite overhead scales with number of disposables Dispose promptly to free resources 10.3. Cancellation Speed Cancellation is immediate for Disposable.Swap Disposable.Composite disposes all children in sequence Consider timeout strategies for long-running operations 11. Conclusion Proper management of reactive resources is crucial for building robust Spring Boot applications with Project Reactor. Understanding when and how to use Disposable, Disposable.Composite, and Disposable.Swap enables you to: Prevent memory leaks through proper resource cleanup Dynamically switch between active operations seamlessly Manage multiple subscriptions efficiently Build responsive applications with search-as-you-type and real-time features Key takeaways: Use Disposable for single subscriptions Use Disposable.Composite for managing multiple related resources Use Disposable.Swap for dynamic replacement of active operations Always clean up resources with @PreDestroy Add proper logging and error handling The complete source code is available on GitHub Gist. 12. Resources Project Reactor Disposable API Reactor Reference: Cancelling a Subscribe Spring Shutdown Callbacks Project Reactor Reference Guide ","language":"en","objectID":"3931cff8bc4cfa2ebbc9836c5c05af86","tags":["Java","Spring Boot","Reactor","Reactive Programming","Resource Management"],"title":"Reactor Disposable Management: Composite and Swap","type":"article","url":"https://www.maoudia.com/blog/reactor-disposable-management/"},{"author":"Moncef AOUDIA","categories":["Tutorial","Reactive Programming"],"content":" When exploring directory structures in a reactive programming environment, the strategies of breadth-first and depth-first traversal play a crucial role. This guide explores how to use Reactor’s expand and expandDeep operators to traverse and emit paths in a reactive stream. Table of contents 1. Overview 2. Traversal Strategies 3. Project Setup 4. Implementation 5. Testing 6. Use Cases and Recommendations 7. Best Practices 8. Performance Considerations 9. Comparison Summary 10. Conclusion 11. Resources 1. Overview Project Reactor provides two powerful operators for recursive exploration: expand (breadth-first) and expandDeep (depth-first). These operators are particularly useful when working with hierarchical structures like file systems, where you need to traverse directories and process files reactively. The ReactorFileUtils class demonstrates practical implementations of both strategies for exploring directory structures in a non-blocking, reactive manner. 2. Traversal Strategies 2.1. Breadth-First Traversal Breadth-first traversal explores a tree structure level by level, processing all nodes at the current depth before moving to the next level. Failed to generate image: mmdc failed: Error: Failed to launch the browser process! [1202/155047.335839:FATAL:zygote_host_impl_linux.cc(128)] No usable sandbox! If you are running on Ubuntu 23.10+ or another Linux distro that has disabled unprivileged user namespaces with AppArmor, see https://chromium.googlesource.com/chromium/src/+/main/docs/security/apparmor-userns-restrictions.md. Otherwise see https://chromium.googlesource.com/chromium/src/+/main/docs/linux/suid_sandbox_development.md for more information on developing with the (older) SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox. TROUBLESHOOTING: https://pptr.dev/troubleshooting at Interface.onClose (file:///home/runner/work/www.maoudia.com/www.maoudia.com/node_modules/@puppeteer/browsers/lib/esm/launch.js:303:24) at Interface.emit (node:events:539:35) at Interface.close (node:readline:586:8) at Socket.onend (node:readline:277:10) at Socket.emit (node:events:539:35) at endReadableNT (node:internal/streams/readable:1345:12) at processTicksAndRejections (node:internal/process/task_queues:83:21) %%{init: {\u0026#39;theme\u0026#39;:\u0026#39;neutral\u0026#39;, \u0026#39;themeVariables\u0026#39;: { \u0026#39;fontSize\u0026#39;:\u0026#39;18px\u0026#39;}}}%% graph TB A[\u0026#34;A\u0026lt;br/\u0026gt;(Level 0)\u0026#34;] B[\u0026#34;B\u0026lt;br/\u0026gt;(Level 1)\u0026#34;] C[\u0026#34;C\u0026lt;br/\u0026gt;(Level 1)\u0026#34;] D[\u0026#34;D\u0026lt;br/\u0026gt;(Level 2)\u0026#34;] E[\u0026#34;E\u0026lt;br/\u0026gt;(Level 2)\u0026#34;] F[\u0026#34;F\u0026lt;br/\u0026gt;(Level 2)\u0026#34;] G[\u0026#34;G\u0026lt;br/\u0026gt;(Level 2)\u0026#34;] A --\u0026gt; B A --\u0026gt; C B --\u0026gt; D B --\u0026gt; E C --\u0026gt; F C --\u0026gt; G Order[\u0026#34;\u0026lt;b\u0026gt;Traversal Order:\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt;A → B → C → D → E → F → G\u0026#34;] classDef level0 fill:#2563eb,stroke:#1e40af,color:#fff,stroke-width:3px classDef level1 fill:#10b981,stroke:#059669,color:#fff,stroke-width:2px classDef level2 fill:#f59e0b,stroke:#d97706,color:#fff,stroke-width:2px classDef info fill:#f3f4f6,stroke:#9ca3af,color:#111,stroke-width:2px class A level0 class B,C level1 class D,E,F,G level2 class Order info 2.1.1. Characteristics Starting Point: Begins with the root directory path Exploration: Checks if the path is a directory, lists immediate child paths, and emits them level by level Processing Order: Processes all immediate neighbors before moving deeper Use Case: Useful when you need to process directories closest to the root first 2.1.2. Example For a directory structure A → B, C → D, E, the exploration order is: A (root) B, C (level 1) D, E (level 2) 2.2. Depth-First Traversal Depth-first traversal explores a tree structure by going as deep as possible along each branch before backtracking. Failed to generate image: mmdc failed: Error: Failed to launch the browser process! [1202/155047.807809:FATAL:zygote_host_impl_linux.cc(128)] No usable sandbox! If you are running on Ubuntu 23.10+ or another Linux distro that has disabled unprivileged user namespaces with AppArmor, see https://chromium.googlesource.com/chromium/src/+/main/docs/security/apparmor-userns-restrictions.md. Otherwise see https://chromium.googlesource.com/chromium/src/+/main/docs/linux/suid_sandbox_development.md for more information on developing with the (older) SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox. TROUBLESHOOTING: https://pptr.dev/troubleshooting at Interface.onClose (file:///home/runner/work/www.maoudia.com/www.maoudia.com/node_modules/@puppeteer/browsers/lib/esm/launch.js:303:24) at Interface.emit (node:events:539:35) at Interface.close (node:readline:586:8) at Socket.onend (node:readline:277:10) at Socket.emit (node:events:539:35) at endReadableNT (node:internal/streams/readable:1345:12) at processTicksAndRejections (node:internal/process/task_queues:83:21) %%{init: {\u0026#39;theme\u0026#39;:\u0026#39;neutral\u0026#39;, \u0026#39;themeVariables\u0026#39;: { \u0026#39;fontSize\u0026#39;:\u0026#39;18px\u0026#39;}}}%% graph TB A[\u0026#34;A\u0026lt;br/\u0026gt;(Start)\u0026#34;] B[\u0026#34;B\u0026lt;br/\u0026gt;(Branch 1)\u0026#34;] C[\u0026#34;C\u0026lt;br/\u0026gt;(Branch 2)\u0026#34;] D[\u0026#34;D\u0026lt;br/\u0026gt;(Deep 1)\u0026#34;] E[\u0026#34;E\u0026lt;br/\u0026gt;(Deep 2)\u0026#34;] F[\u0026#34;F\u0026lt;br/\u0026gt;(Deep 3)\u0026#34;] G[\u0026#34;G\u0026lt;br/\u0026gt;(Deep 4)\u0026#34;] A --\u0026gt; B A --\u0026gt; C B --\u0026gt; D B --\u0026gt; E C --\u0026gt; F C --\u0026gt; G Order[\u0026#34;\u0026lt;b\u0026gt;Traversal Order:\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt;A → B → D → E → C → F → G\u0026#34;] classDef root fill:#2563eb,stroke:#1e40af,color:#fff,stroke-width:3px classDef branch fill:#7B68EE,stroke:#5C4DB8,color:#fff,stroke-width:2px classDef deep fill:#f59e0b,stroke:#d97706,color:#fff,stroke-width:2px classDef info fill:#f3f4f6,stroke:#9ca3af,color:#111,stroke-width:2px class A root class B,C branch class D,E,F,G deep class Order info 2.2.1. Characteristics Starting Point: Starts with the root directory path Exploration: Checks if the path is a directory, lists immediate child paths, and recursively explores each branch completely Processing Order: Goes as deep as possible before backtracking Use Case: Useful for fully exploring specific branches before moving on 2.2.2. Example For a directory structure A → B, C → D, E, the exploration order is: A (root) B (first branch) D, E (explore B’s children completely) C (backtrack and move to second branch) 3. Project Setup 3.1. Requirements OpenJDK 21.0.x or higher Maven 3.6.x or higher Project Reactor 3.6.x 3.2. Maven Configuration pom.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.maoudia.lib\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;app\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;maoudia-lib\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;MAOUDIA LIB\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;21\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.projectreactor\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;reactor-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.projectreactor\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;reactor-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 4. Implementation 4.1. ReactorFileUtils Class This utility class provides reactive file operations using Project Reactor. ReactorFileUtils.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package com.maoudia; import jakarta.validation.constraints.NotNull; import reactor.core.publisher.Flux; import reactor.core.publisher.Mono; import reactor.util.annotation.NonNull; import java.io.File; import java.nio.file.Files; import java.nio.file.Path; public class ReactorFileUtils { @NotNull public static Flux\u0026lt;Path\u0026gt; expand(@NonNull Path path) { (1) return Mono.justOrEmpty(path) .filter(Files::isDirectory) .expand(ReactorFileUtils::listPaths); } @NotNull public static Flux\u0026lt;Path\u0026gt; expandDeep(@NonNull Path path) { (2) return Mono.justOrEmpty(path) .filter(Files::isDirectory) .expandDeep(ReactorFileUtils::listPaths); } @NotNull public static Flux\u0026lt;Path\u0026gt; listPaths(@NonNull Path path) { (3) return Mono.justOrEmpty(path) .filter(Files::isDirectory) .mapNotNull(directory -\u0026gt; directory.toFile().listFiles()) .flatMapMany(Flux::fromArray) .map(File::toPath); } } 1 Breadth-first traversal: explores directories level by level using expand operator. 2 Depth-first traversal: explores directories deeply along each branch using expandDeep operator. 3 Lists all paths within a directory and emits them as a reactive stream. 4.2. Understanding the Implementation 4.2.1. expand Method The expand method implements breadth-first traversal: return Mono.justOrEmpty(path) .filter(Files::isDirectory) .expand(ReactorFileUtils::listPaths); Creates a Mono from the input path Filters to ensure it’s a directory Uses expand to recursively list paths, processing each level completely before moving deeper 4.2.2. expandDeep Method The expandDeep method implements depth-first traversal: return Mono.justOrEmpty(path) .filter(Files::isDirectory) .expandDeep(ReactorFileUtils::listPaths); Creates a Mono from the input path Filters to ensure it’s a directory Uses expandDeep to recursively explore each branch fully before backtracking 4.2.3. listPaths Method The listPaths method provides the expansion logic: return Mono.justOrEmpty(path) .filter(Files::isDirectory) .mapNotNull(directory -\u0026gt; directory.toFile().listFiles()) .flatMapMany(Flux::fromArray) .map(File::toPath); Creates a Mono from the path Filters directories only Lists all files in the directory Converts the array to a Flux Maps each File to a Path 5. Testing 5.1. Test Structure The tests use StepVerifier from reactor-test to verify the traversal order: ReactorFileUtilsTest.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 package com.maoudia; import org.junit.jupiter.api.Test; import reactor.core.publisher.Flux; import reactor.test.StepVerifier; import java.nio.file.Path; import java.nio.file.Paths; class ReactorFileUtilsTest { private static final Path ROOT_DIRECTORY = Paths.get(\u0026#34;src/test/resources\u0026#34;); @Test void expand_ValidPath_ReturnsExpectedPaths() { (1) Flux\u0026lt;Path\u0026gt; pathFlux = ReactorFileUtils.expand(ROOT_DIRECTORY); StepVerifier.create(pathFlux) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;resources\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;file2.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;file1.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subdirectory\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;emptydirectory\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subfile1.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subfile2.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subsubdirectory\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subsubfile1.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subsubfile2.txt\u0026#34;)) .verifyComplete(); } @Test void expand_NullPath_ReturnsEmptyFlux() { (2) Flux\u0026lt;Path\u0026gt; pathFlux = ReactorFileUtils.expand(null); StepVerifier.create(pathFlux) .verifyComplete(); } @Test void expandDeep_ValidPath_ReturnsExpectedPaths() { (3) Flux\u0026lt;Path\u0026gt; pathFlux = ReactorFileUtils.expandDeep(ROOT_DIRECTORY); StepVerifier.create(pathFlux) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;resources\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;file2.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;file1.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subdirectory\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subfile1.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subfile2.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subsubdirectory\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subsubfile1.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subsubfile2.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;emptydirectory\u0026#34;)) .verifyComplete(); } @Test void expandDeep_NullPath_ReturnsEmptyFlux() { (4) Flux\u0026lt;Path\u0026gt; pathFlux = ReactorFileUtils.expand(null); StepVerifier.create(pathFlux) .verifyComplete(); } @Test void listFiles_ValidDirectory_ReturnsExpectedPaths() { (5) Flux\u0026lt;Path\u0026gt; pathFlux = ReactorFileUtils.listPaths(ROOT_DIRECTORY); StepVerifier.create(pathFlux) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;file2.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;file1.txt\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;subdirectory\u0026#34;)) .expectNextMatches(path -\u0026gt; path.endsWith(\u0026#34;emptydirectory\u0026#34;)) .verifyComplete(); } @Test void listFiles_NullPath_ReturnsEmptyFlux() { (6) Flux\u0026lt;Path\u0026gt; pathFlux = ReactorFileUtils.listPaths(null); StepVerifier.create(pathFlux) .verifyComplete(); } } 1 Tests breadth-first traversal, verifying that paths are emitted level by level. 2 Tests null path handling for expand method, expecting an empty flux. 3 Tests depth-first traversal, verifying that paths are emitted branch by branch. 4 Tests null path handling for expandDeep method, expecting an empty flux. 5 Tests listing immediate children of a directory without recursion. 6 Tests null path handling for listPaths method, expecting an empty flux. 5.2. Test Directory Structure The tests assume the following directory structure in src/test/resources: resources/ ├── file1.txt ├── file2.txt ├── emptydirectory/ └── subdirectory/ ├── subfile1.txt ├── subfile2.txt └── subsubdirectory/ ├── subsubfile1.txt └── subsubfile2.txt 5.3. Observing Traversal Differences Notice the difference in traversal order between the two tests: Breadth-First (expand): resources → file2.txt → file1.txt → subdirectory → emptydirectory → subfile1.txt → subfile2.txt → subsubdirectory → subsubfile1.txt → subsubfile2.txt Depth-First (expandDeep): resources → file2.txt → file1.txt → subdirectory → subfile1.txt → subfile2.txt → subsubdirectory → subsubfile1.txt → subsubfile2.txt → emptydirectory The key difference: emptydirectory appears earlier in breadth-first (same level as subdirectory) but later in depth-first (after fully exploring subdirectory). 6. Use Cases and Recommendations 6.1. When to Use Breadth-First (expand) Finding files at specific depths: When you need to process all files at a certain level before going deeper Memory efficiency: When exploring very deep hierarchies where depth-first might cause stack issues Immediate neighbor processing: When you need to process files closest to the root first Load balancing: When distributing work across multiple levels 6.2. When to Use Depth-First (expandDeep) Complete branch exploration: When you need to fully process one directory tree before moving to siblings Resource cleanup: When processing requires completing an entire branch before starting another Path-dependent operations: When operations depend on completing parent-child relationships Search optimization: When looking for specific files and want to explore paths completely 7. Best Practices 7.1. Error Handling Add proper error handling to the reactive chain: ReactorFileUtils.expand(path) .onErrorResume(IOException.class, e -\u0026gt; { log.error(\u0026#34;Failed to traverse directory\u0026#34;, e); return Flux.empty(); }) .subscribe(); 7.2. Backpressure Management For large directory structures, consider using backpressure operators: ReactorFileUtils.expand(path) .limitRate(100) .onBackpressureBuffer(1000) .subscribe(); 7.3. Resource Management Ensure proper resource cleanup when working with file streams: ReactorFileUtils.expand(path) .doOnCancel(() -\u0026gt; log.info(\u0026#34;Traversal cancelled\u0026#34;)) .doFinally(signalType -\u0026gt; log.info(\u0026#34;Traversal completed: {}\u0026#34;, signalType)) .subscribe(); 7.4. Filtering and Transformation Combine traversal with filtering and transformation: ReactorFileUtils.expand(path) .filter(p -\u0026gt; p.toString().endsWith(\u0026#34;.txt\u0026#34;)) .map(Path::getFileName) .subscribe(System.out::println); 8. Performance Considerations 8.1. Memory Usage Breadth-first: Uses more memory as it needs to keep track of all nodes at the current level Depth-first: Uses less memory but may have deeper recursion stacks 8.2. Processing Speed Breadth-first: Better for parallel processing of same-level items Depth-first: Better for sequential processing of complete branches 8.3. Cancellation Both strategies support cancellation through Reactor’s subscription mechanism: Disposable subscription = ReactorFileUtils.expand(path) .subscribe(System.out::println); subscription.dispose(); 9. Comparison Summary Aspect Breadth-First (expand) Depth-First (expandDeep) Traversal Order Level by level Branch by branch Processing Immediate neighbors first Complete branch exploration Memory Usage Higher (stores level nodes) Lower (recursive depth) Use Case Level-based operations Branch-based operations Best For Finding files at specific depths Complete directory processing 10. Conclusion Understanding the difference between breadth-first and depth-first traversal is crucial for efficient reactive directory exploration. Project Reactor’s expand and expandDeep operators provide powerful tools for implementing these strategies in a non-blocking, reactive manner. Key takeaways: Use expand (breadth-first) when you need to process directories level by level Use expandDeep (depth-first) when you need to fully explore branches before moving on Both strategies integrate seamlessly with Reactor’s reactive programming model Choose the appropriate strategy based on your specific use case and requirements The complete source code is available on GitHub Gist. 11. Resources Flux Expand vs ExpandDeep Tutorial Project Reactor Reference Guide Reactor Core Javadoc Reactor Test Documentation ","language":"en","objectID":"feb4ba2f03ce0a2e65764ef6cec07860","tags":["Java","Reactor","Reactive Programming","Project Reactor","File System"],"title":"Reactor Expand vs ExpandDeep: Directory Traversal Strategies","type":"article","url":"https://www.maoudia.com/blog/reactor-expand-vs-expanddeep/"},{"author":"Moncef AOUDIA","categories":["Tutorial"],"content":" This guide demonstrates configuring asynchronous logging with Logback in a Spring Boot application. This approach provides improved performance, reduced latency, scalability, and fault tolerance. By leveraging existing Spring logging configuration properties, we can customize the logging behavior according to your application’s requirements seamlessly based on the environment variables declared in Spring Boot’s default Logback configuration. Table of Contents 1. Overview 2. Synchronous vs Asynchronous Logging 2.1. Key Differences 3. Benefits of Async Logging 3.1. Improved Performance 3.2. Reduced Latency 3.3. Scalability 3.4. Fault Tolerance 4. AsyncAppender Configuration Parameters 4.1. queueSize 4.2. discardingThreshold 4.3. includeCallerData 4.4. maxFlushTime 4.5. neverBlock 5. Project Setup 5.1. Requirements 6. Configuration 6.1. Application Properties 6.2. Logback Configuration 7. Understanding Spring Boot Logging Defaults 7.1. defaults.xml 7.2. base.xml 7.3. DefaultLogbackConfiguration.java 8. Use Cases and Recommendations 8.1. Development Environment 8.2. Production Environment 8.3. High-Throughput Applications 9. Best Practices 9.1. Monitor Queue Size 9.2. Graceful Shutdown 9.3. Avoid includeCallerData in Production 9.4. Use Appropriate Log Levels 10. Troubleshooting 10.1. Logs Not Appearing 10.2. Performance Issues 10.3. Lost Log Events 11. Conclusion 12. Resources 1. Overview Asynchronous logging is a powerful technique that offloads the logging operations to a separate thread, preventing the main application threads from blocking on I/O operations. This is particularly beneficial for high-throughput applications where logging can become a bottleneck. The AsyncAppender in Logback wraps both console and file appenders to enable asynchronous logging, enhancing performance and fault tolerance. It uses a blocking queue to buffer log events and processes them asynchronously. Contrary to the default Spring Boot configuration, file logging (ASYNC_FILE) is enabled in this setup even if logging.file.name or logging.file.path are not explicitly configured. 2. Synchronous vs Asynchronous Logging Understanding the fundamental difference between synchronous and asynchronous logging is crucial for making the right choice for your application. Failed to generate image: mmdc failed: Error: Failed to launch the browser process! [1202/155048.746951:FATAL:zygote_host_impl_linux.cc(128)] No usable sandbox! If you are running on Ubuntu 23.10+ or another Linux distro that has disabled unprivileged user namespaces with AppArmor, see https://chromium.googlesource.com/chromium/src/+/main/docs/security/apparmor-userns-restrictions.md. Otherwise see https://chromium.googlesource.com/chromium/src/+/main/docs/linux/suid_sandbox_development.md for more information on developing with the (older) SUID sandbox. If you want to live dangerously and need an immediate workaround, you can try using --no-sandbox. TROUBLESHOOTING: https://pptr.dev/troubleshooting at Interface.onClose (file:///home/runner/work/www.maoudia.com/www.maoudia.com/node_modules/@puppeteer/browsers/lib/esm/launch.js:303:24) at Interface.emit (node:events:539:35) at Interface.close (node:readline:586:8) at Socket.onend (node:readline:277:10) at Socket.emit (node:events:539:35) at endReadableNT (node:internal/streams/readable:1345:12) at processTicksAndRejections (node:internal/process/task_queues:83:21) %%{init: {\u0026#39;theme\u0026#39;:\u0026#39;neutral\u0026#39;, \u0026#39;themeVariables\u0026#39;: { \u0026#39;fontSize\u0026#39;:\u0026#39;16px\u0026#39;, \u0026#39;fontFamily\u0026#39;:\u0026#39;Arial\u0026#39;}}}%% graph TB subgraph Sync[\u0026#34;\u0026lt;b\u0026gt;Synchronous Logging\u0026lt;/b\u0026gt;\u0026#34;] direction TB ST[\u0026#34;Application Thread\u0026#34;] ST --\u0026gt;|1. Log Event| SL[\u0026#34;Logger\u0026#34;] SL --\u0026gt;|2. Write to Disk/Console| SO[\u0026#34;I/O Operation\u0026lt;br/\u0026gt;\u0026lt;b\u0026gt;⏱️ BLOCKS THREAD\u0026lt;/b\u0026gt;\u0026#34;] SO --\u0026gt;|3. Wait for completion| SL SL --\u0026gt;|4. Return control| ST SyncMetrics[\u0026#34;\u0026lt;b\u0026gt;Characteristics:\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt;❌ Thread blocked during I/O\u0026lt;br/\u0026gt;❌ Higher latency\u0026lt;br/\u0026gt;❌ Lower throughput\u0026lt;br/\u0026gt;❌ Simple implementation\u0026#34;] end subgraph Async[\u0026#34;\u0026lt;b\u0026gt;Asynchronous Logging\u0026lt;/b\u0026gt;\u0026#34;] direction TB AT[\u0026#34;Application Thread\u0026#34;] AT --\u0026gt;|1. Log Event| AQ[\u0026#34;Blocking Queue\u0026lt;br/\u0026gt;(Buffer)\u0026#34;] AQ -.-\u0026gt;|2. Immediate return\u0026lt;br/\u0026gt;\u0026lt;b\u0026gt;✓ NON-BLOCKING\u0026lt;/b\u0026gt;| AT AQ --\u0026gt;|3. Dequeue| AW[\u0026#34;Worker Thread\u0026#34;] AW --\u0026gt;|4. Write to Disk/Console| AO[\u0026#34;I/O Operation\u0026#34;] AsyncMetrics[\u0026#34;\u0026lt;b\u0026gt;Characteristics:\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt;✓ Non-blocking operation\u0026lt;br/\u0026gt;✓ Reduced latency\u0026lt;br/\u0026gt;✓ Higher throughput\u0026lt;br/\u0026gt;✓ Better scalability\u0026#34;] end classDef syncStyle fill:#ef4444,stroke:#dc2626,color:#fff,stroke-width:2px classDef asyncStyle fill:#10b981,stroke:#059669,color:#fff,stroke-width:2px classDef metricsStyle fill:#f3f4f6,stroke:#9ca3af,color:#111,stroke-width:1px class ST,SL,SO syncStyle class AT,AQ,AW,AO asyncStyle class SyncMetrics,AsyncMetrics metricsStyle 2.1. Key Differences Aspect Synchronous Logging Asynchronous Logging Thread Behavior Application thread blocks until log is written Application thread returns immediately Performance Impact Direct impact on request processing time Minimal impact on request processing Latency Higher latency due to I/O blocking Lower latency, I/O handled separately Throughput Limited by I/O operations Higher throughput, decoupled from I/O Complexity Simple, straightforward More complex, requires queue management Use Case Low-volume logging, simple applications High-volume logging, performance-critical apps 3. Benefits of Async Logging 3.1. Improved Performance Asynchronous logging reduces the time the application thread spends on logging operations by delegating them to a separate thread. 3.2. Reduced Latency Main application threads are not blocked waiting for log operations to complete, resulting in lower response times. 3.3. Scalability Better resource utilization allows the application to handle more concurrent requests. 3.4. Fault Tolerance If the logging system experiences temporary issues, the application continues to function normally while log events are queued. 4. AsyncAppender Configuration Parameters Logback’s AsyncAppender provides several configuration parameters to fine-tune its behavior: 4.1. queueSize Default Value: 256 Description: Maximum capacity of the blocking queue that buffers log events. Usage: Increase for high-volume logging scenarios, but be mindful of memory consumption. 4.2. discardingThreshold Default Value: 20% of queue size Description: By default, drops events of level TRACE, DEBUG, and INFO when the queue has 20% capacity remaining. Set to 0 to keep all events. Usage: Prevents queue overflow by discarding low-priority events when the queue is nearly full. 4.3. includeCallerData Default Value: false Description: Controls whether to extract caller data (class name, method name, line number). Usage: Set to true only if you need caller information, as extracting this data is expensive and impacts performance. 4.4. maxFlushTime Default Value: Not set Description: Maximum time in milliseconds the AsyncAppender waits for the queue to flush during application shutdown. Usage: Ensures log events are not lost during graceful shutdown. 4.5. neverBlock Default Value: false Description: When false, the appender blocks on a full queue. When true, it drops the message instead. Usage: Set to true if you prefer dropping log events over blocking application threads. 5. Project Setup 5.1. Requirements OpenJDK 11.0.x or higher Maven 3.6.x or higher Spring Boot 2.x or 3.x 6. Configuration 6.1. Application Properties Configure basic logging properties in application.yml: application.yml 1 2 3 4 5 logging: file: name: tutorial pattern: console: \u0026#34;%d{yyyy-MM-dd HH:mm:ss.SSSZZ} %magenta([%thread]) [%logger{36}] %highlight(%level) %cyan([%class{0}.%method:%line]) - %message%n%xException}\u0026#34; This configuration: Sets the log file name to tutorial Customizes the console log pattern with colors and detailed information including timestamp, thread, logger name, log level, class/method/line, and message 6.2. Logback Configuration Create logback-spring.xml in src/main/resources: logback-spring.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;configuration debug=\u0026#34;true\u0026#34; scan=\u0026#34;true\u0026#34; \u0026gt; \u0026lt;statusListener class=\u0026#34;ch.qos.logback.core.status.OnConsoleStatusListener\u0026#34; /\u0026gt; \u0026lt;include resource=\u0026#34;org/springframework/boot/logging/logback/defaults.xml\u0026#34; /\u0026gt; (1) \u0026lt;property name=\u0026#34;LOG_FILE\u0026#34; value=\u0026#34;${LOG_FILE:-${LOG_PATH:-${LOG_TEMP:-${java.io.tmpdir:-/tmp}}}/spring.log}\u0026#34;/\u0026gt; (2) \u0026lt;include resource=\u0026#34;org/springframework/boot/logging/logback/console-appender.xml\u0026#34; /\u0026gt; (3) \u0026lt;include resource=\u0026#34;org/springframework/boot/logging/logback/file-appender.xml\u0026#34; /\u0026gt; (4) \u0026lt;appender name=\u0026#34;ASYNC_CONSOLE\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; (5) \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34; /\u0026gt; \u0026lt;queueSize\u0026gt;256\u0026lt;/queueSize\u0026gt; \u0026lt;includeCallerData\u0026gt;false\u0026lt;/includeCallerData\u0026gt; \u0026lt;neverBlock\u0026gt;false\u0026lt;/neverBlock\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;ASYNC_FILE\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; (6) \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34;/\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;INFO\u0026#34;\u0026gt; (7) \u0026lt;appender-ref ref=\u0026#34;ASYNC_CONSOLE\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;ASYNC_FILE\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 1 Include Spring Boot’s default Logback configurations, providing access to predefined properties and converters. 2 Define the log file location with fallback values: LOG_FILE → LOG_PATH → LOG_TEMP → java.io.tmpdir → /tmp/spring.log. 3 Include Spring Boot’s default console appender configuration. 4 Include Spring Boot’s default file appender configuration. 5 Configure the async console appender wrapping the standard CONSOLE appender with all available parameters shown. 6 Configure the async file appender wrapping the standard FILE appender using default parameter values. 7 Set the root logger level to INFO and attach both async appenders. The debug=\u0026#34;true\u0026#34; and scan=\u0026#34;true\u0026#34; attributes in the configuration element enable: debug: Prints Logback’s internal status information to help troubleshoot configuration issues. scan: Automatically reloads the configuration file when it changes (useful during development). 7. Understanding Spring Boot Logging Defaults Spring Boot provides a well-structured default Logback configuration that you can leverage and extend. The key files include: 7.1. defaults.xml Contains conversion rules, patterns, and property definitions used by Spring Boot. Available at: https://github.com/spring-projects/spring-boot/blob/3.5.x/spring-boot-project/spring-boot/src/main/resources/org/springframework/boot/logging/logback/defaults.xml 7.2. base.xml Provides the base configuration including console and file appenders. Available at: https://github.com/spring-projects/spring-boot/blob/3.5.x/spring-boot-project/spring-boot/src/main/resources/org/springframework/boot/logging/logback/base.xml 7.3. DefaultLogbackConfiguration.java The Java source that programmatically configures Logback when no custom configuration is provided. Available at: https://github.com/spring-projects/spring-boot/blob/3.5.x/spring-boot-project/spring-boot/src/main/java/org/springframework/boot/logging/logback/DefaultLogbackConfiguration.java 8. Use Cases and Recommendations 8.1. Development Environment For development, you might want to disable async logging or use only console logging for immediate feedback: \u0026lt;root level=\u0026#34;DEBUG\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; 8.2. Production Environment In production, enable both async console and file logging with appropriate queue sizes: \u0026lt;appender name=\u0026#34;ASYNC_CONSOLE\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34; /\u0026gt; \u0026lt;queueSize\u0026gt;512\u0026lt;/queueSize\u0026gt; \u0026lt;neverBlock\u0026gt;true\u0026lt;/neverBlock\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;ASYNC_FILE\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34;/\u0026gt; \u0026lt;queueSize\u0026gt;512\u0026lt;/queueSize\u0026gt; \u0026lt;includeCallerData\u0026gt;false\u0026lt;/includeCallerData\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;INFO\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;ASYNC_CONSOLE\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;ASYNC_FILE\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; 8.3. High-Throughput Applications For applications with very high logging volume: Increase queueSize to 1024 or higher Set neverBlock to true to prevent application threads from blocking Consider setting discardingThreshold to a higher value to drop low-priority logs earlier Keep includeCallerData as false for maximum performance 9. Best Practices 9.1. Monitor Queue Size Monitor the async appender queue to ensure it’s not frequently reaching capacity. If it does, consider: Increasing the queue size Reducing log volume by adjusting log levels Optimizing the underlying appender performance 9.2. Graceful Shutdown Ensure your application allows time for the async appender to flush remaining log events during shutdown. Configure maxFlushTime appropriately: \u0026lt;appender name=\u0026#34;ASYNC_FILE\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34;/\u0026gt; \u0026lt;maxFlushTime\u0026gt;5000\u0026lt;/maxFlushTime\u0026gt; \u0026lt;/appender\u0026gt; 9.3. Avoid includeCallerData in Production Extracting caller data is expensive. Only enable it if absolutely necessary: \u0026lt;includeCallerData\u0026gt;false\u0026lt;/includeCallerData\u0026gt; 9.4. Use Appropriate Log Levels Set proper log levels for different packages to avoid overwhelming the async queue: \u0026lt;logger name=\u0026#34;com.myapp.verbose.package\u0026#34; level=\u0026#34;WARN\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;org.springframework\u0026#34; level=\u0026#34;INFO\u0026#34;/\u0026gt; \u0026lt;logger name=\u0026#34;org.hibernate\u0026#34; level=\u0026#34;WARN\u0026#34;/\u0026gt; 10. Troubleshooting 10.1. Logs Not Appearing If logs are not appearing, check: The queueSize might be too small and events are being discarded Set debug=\u0026#34;true\u0026#34; in the configuration to see Logback’s internal status Verify the log file path is writable 10.2. Performance Issues If async logging doesn’t improve performance: Ensure includeCallerData is false Increase queueSize if the queue is frequently full Consider using neverBlock=\u0026#34;true\u0026#34; to prevent thread blocking Check if the underlying appender (file I/O) is the bottleneck 10.3. Lost Log Events If you’re losing log events: Increase queueSize Set discardingThreshold=\u0026#34;0\u0026#34; to keep all events Configure maxFlushTime to ensure events are flushed during shutdown Consider using neverBlock=\u0026#34;false\u0026#34; to block rather than drop events 11. Conclusion Asynchronous logging with Logback in Spring Boot provides significant performance benefits for high-throughput applications. By properly configuring the AsyncAppender, you can: Reduce application latency by offloading logging to separate threads Improve throughput by preventing main threads from blocking on I/O Maintain fault tolerance with configurable queue management Customize behavior based on environment-specific requirements The configuration demonstrated here leverages Spring Boot’s default Logback setup while adding async capabilities, making it easy to integrate into existing applications. The complete source code is available on GitHub Gist. 12. Resources Logback Manual: AsyncAppender Logback Performance Optimization Spring Boot Documentation: Logging Features Spring Boot Default Logback Configuration Spring Boot Documentation: File-Only Output Spring Boot Documentation: Custom Log Configuration ","language":"en","objectID":"99cb28bce3385312c9ced7e2144b3bb4","tags":["Java","Spring Boot","Logback","Logging","Performance","Best Practices"],"title":"Spring Boot Logback Async Logging","type":"article","url":"https://www.maoudia.com/blog/spring-boot-logback-async-logging/"},{"author":"Moncef AOUDIA","categories":["Tutorial"],"content":" Spring Boot provides flexible error handling configuration options that allow you to control what information is exposed in error responses. This is crucial for maintaining security in production while providing detailed debugging information in development environments. This tutorial showcases varying error response behaviors across different deployment profiles using a REST controller that intentionally throws errors for demonstration purposes. Table of contents 1. Error Configuration Options 2. Environment-Specific Profiles 3. Project Setup 4. Application Configuration 5. Implementation 6. Testing Error Responses 7. Best Practices 8. Conclusion 9. Resources 1. Error Configuration Options Spring Boot offers six key configurable error properties that control error response behavior: 1.1. Include Binding Errors Controls visibility of validation errors in form submissions. Default Value: NEVER Possible Values: ALWAYS, NEVER, ON_PARAM Description: Specifies whether binding errors, such as validation errors in form submissions, should be included in error responses. 1.2. Include Exception Toggles detailed exception information in responses. Default Value: false Possible Values: true, false Description: Specifies whether detailed exception information should be included in error responses. 1.3. Include Message Manages error message visibility. Default Value: NEVER Possible Values: ALWAYS, NEVER, ON_PARAM Description: Specifies whether error messages should be included in error responses. 1.4. Include Stack Trace Determines stack trace inclusion in error responses. Default Value: NEVER Possible Values: ALWAYS, NEVER, ON_PARAM Description: Specifies whether stack traces should be included in error responses. 1.5. Error Controller Path Default location for error handling. Default Value: /error Possible Values: Any valid URL path Description: Defines the path of the error controller, which handles error requests. 1.6. Whitelabel Error Page Enables or disables the default error page displayed in browsers. Default Value: true Possible Values: true, false Description: Specifies whether to enable the default Whitelabel Error Page displayed in browsers in case of a server error. Understanding the configuration values: ALWAYS: Always include or enable the corresponding attribute or feature. NEVER: Never include or enable the corresponding attribute or feature. ON_PARAM: Include or enable the corresponding attribute or feature based on the presence of a specific query parameter. 2. Environment-Specific Profiles 2.1. Development Environment Configuration for development profiles (local, test, dev): Include Binding Errors: ALWAYS Include Exception: true Include Message: ALWAYS Include Stack Trace: ALWAYS All error details are included to facilitate debugging and development. 2.2. QA and Staging Environment Configuration for QA and staging profiles: Include Binding Errors: ON_PARAM Include Exception: true Include Message: ON_PARAM Include Stack Trace: ON_PARAM Details are shown conditionally via query parameters (e.g., ?trace=true). 2.3. Production Environment Configuration for production profile: Whitelabel Error Page Enabled: false Whitelabel error page is disabled for security, omitting sensitive details entirely. 3. Project Setup 3.1. Requirements OpenJDK 21.0.x Maven 3.9.x Spring Boot 3.2.3 3.2. Maven Configuration The project uses Spring Boot 3.2.3 with Java 21. pom.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.3\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.maoudia\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;app\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;maoudia-app\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;MAOUDIA APP\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;21\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;21\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 4. Application Configuration 4.1. Error Configuration The application configuration demonstrates profile-based error handling settings. application.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 server: port: 8080 error: include-binding-errors: NEVER include-exception: OFF include-message: NEVER include-stacktrace: NEVER path: /error whitelabel: enabled: ON spring: application: name: app --- spring.config.activate.on-profile: local, test, dev server: error: include-binding-errors: ALWAYS include-exception: ON include-message: ALWAYS include-stacktrace: ALWAYS --- spring.config.activate.on-profile: qa, staging server: error: include-binding-errors: ON_PARAM include-exception: ON include-message: ON_PARAM include-stacktrace: ON_PARAM --- spring.config.activate.on-profile: prod server: error: whitelabel: enabled: OFF 5. Implementation 5.1. Error Resource Controller We create a REST controller with an endpoint that intentionally throws errors to showcase error handling behavior. ErrorResource.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package com.maoudia; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class ErrorResource { /** * Endpoint to intentionally throw an error. * * @return ResponseEntity containing an error message */ @GetMapping(\u0026#34;/throw\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; throwError() { // Simulate an error by throwing a RuntimeException throw new RuntimeException(\u0026#34;This endpoint always throws an error.\u0026#34;); } } 6. Testing Error Responses 6.1. Default Configuration Request without any specific profile: 1 curl -X GET http://localhost:8080/throw Response: 1 2 3 4 5 6 { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-27T10:10:03.310+00:00\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/throw\u0026#34; } Notice that no sensitive information is exposed in the default configuration. 6.2. Staging Profile with Query Parameter Request with staging profile and trace=true parameter: 1 curl -X GET http://localhost:8080/throw?trace=true Response: 1 2 3 4 5 6 7 8 { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-27T10:16:25.951+00:00\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;exception\u0026#34;: \u0026#34;java.lang.RuntimeException\u0026#34;, \u0026#34;trace\u0026#34;: \u0026#34;java.lang.RuntimeException: This endpoint always throws an error.\\n\\tat com.maoudia.ErrorResource.throwError(ErrorResource.java:18)\\n\\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\\n...\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/throw\u0026#34; } With the trace=true query parameter in staging environment, the full stack trace is returned for debugging purposes. 6.3. Development Profile When running with development profiles (local, test, dev), all error details are automatically included without requiring query parameters. 6.4. Production Profile In production, the whitelabel error page is disabled, and production requests omit sensitive details entirely, returning only the minimal error information. Enable each profile (e.g., local, test, dev, qa, staging, prod) in your Spring Boot application to see the respective error handling behavior. You can activate a profile using: Command line: --spring.profiles.active=staging Environment variable: SPRING_PROFILES_ACTIVE=staging application.yml: spring.profiles.active=staging 7. Best Practices 7.1. Security Considerations Never expose stack traces in production - They can reveal internal application structure and potential security vulnerabilities. Use conditional disclosure - In staging/QA environments, use ON_PARAM to allow developers to see details only when needed. Disable whitelabel page in production - Custom error pages provide better user experience and don’t expose Spring Boot information. 7.2. Development Efficiency Enable all details in development - Use ALWAYS settings to facilitate debugging. Consistent environment naming - Use clear profile names (dev, qa, staging, prod) across all projects. Document query parameters - Make sure developers know about the ?trace=true option in non-production environments. 7.3. Monitoring and Logging While limiting error details in responses is important for security, ensure comprehensive error logging is enabled in all environments for monitoring and troubleshooting purposes. 8. Conclusion Proper error handling configuration is essential for maintaining security while providing useful debugging information. By leveraging Spring Boot’s profile-based configuration, you can: Expose detailed error information in development environments Provide conditional access to error details in staging/QA Maintain security by limiting error exposure in production Improve developer experience without compromising security The complete source code is available on GitHub Gist. 9. Resources Spring Boot ErrorProperties Documentation Spring Boot Application Properties - Server Section Complete Guide to Exception Handling in Spring Boot Spring Boot Error Handling Reference ","language":"en","objectID":"b31bddec52f4efd60f9a8f25634c8d47","tags":["Java","Spring Boot","Error Handling","Configuration","Best Practices"],"title":"Spring Boot Error Server Configuration","type":"article","url":"https://www.maoudia.com/blog/spring-boot-error-server-configuration/"},{"author":"Moncef AOUDIA","categories":["Tutorial","Reactive Programming"],"content":" Afin de mettre à jour les documents d’une collection MongoDB, on passe souvent par des requêtes de mise à jour, si le volume des données est conséquent, cela peut conduire à des problèmes de performance et une surconsommation des ressources matérielles. On va implémenter une solution pour enrichir et mettre à jour efficacement un grand volume de données en utilisant Spring Data MongoDB Reactive. Sommaire 1. EIP enrichisseur de contenu 1.1. Flux d’intégration 2. Configuration du projet 2.1. Prérequis 2.2. Génération 2.3. Structure 2.4. Conteneurs 2.5. Initialisation des données 3. Application 3.1. Configuration 3.2. Implémentation 3.3. Démo 3.4. Rapport VisuelVM 4. Tests d’intégration 5. Conclusion 6. Ressources Avant de continuer la lecture, si vous n’êtes pas familier avec la pile réactive de Spring et MongoDB, je suggère de consulter la section ressources. 1. EIP enrichisseur de contenu Le modèle d’intégration d’entreprise enrichisseur de contenu permet d’ajouter des informations à un message existant depuis une source externe. Il utilise les informations contenues dans le message entrant pour effectuer l’opération d’enrichissement. On va implémenter une version simplifiée de l\u0026#39;EIP : Message en entrée : représenté par un document MongoDB. Enrichisseur : notre application. Ressource : appel à une API RESTful. Message en sortie : nous ne conserverons que le document enrichi. 1.1. Flux d’intégration L’application va lire les documents adresse, ajouter le produit et sauvegarder les documents enrichis dans la base MongoDB. 2. Configuration du projet 2.1. Prérequis OpenJDK 21.0.x Maven 3.9.x Docker Compose 2.23.x MongoDB Database Tools 100.9.x 2.2. Génération On génère le squelette du projet depuis ","language":"fr","objectID":"c5e2c9df3707312de51b5d12a9fb99db","tags":["EIP","Java","Reactor","MongoDB","Spring Boot","Spring Data","Spring WebFlux","Docker Compose","TestContainers","VisualVM"],"title":"Mise À Jour En Masse Avec Spring Data MongoDB Reactive","type":"article","url":"https://www.maoudia.com/fr/blog/mise-a-jour-en-masse-avec-spring-data-mongodb-reactive/"},{"author":"Moncef AOUDIA","categories":["Tutorial","Reactive Programming"],"content":" In order to update documents in a MongoDB collection, we often use update requests, if the volume of data is too large, it could lead to performance issues and overconsumption of hardware resources. We will implement a solution to enrich and update efficiently a large amount of data using Spring Data MongoDB Reactive. Table of contents 1. EIP content enricher 1.1. Integration flow 2. Project setup 2.1. Requirements 2.2. Generation 2.3. Structure 2.4. Containers 2.5. Data initialization 3. Application 3.1. Configuration 3.2. Implementation 3.3. Demo 3.4. VisuelVM report 4. Integration tests 5. Conclusion 6. Resources Before continuing the reading, if you are not familiar with Spring reactive stack and MongoDB, I suggest you to check the resources section. 1. EIP content enricher Enterprise Integration Pattern Content Enricher appends information to an existing message from an external source. It uses information inside the incoming message to perform the enrichment operation. We will implement a simplified version of the EIP : Input message : represented by a MongoDB document. Enricher : our application. Resource : call to a RESTful API. Output message : we will keep only the enriched document. 1.1. Integration flow The application will read the address documents, add the product and save the enriched documents to the MongoDB database. 2. Project setup 2.1. Requirements OpenJDK 21.0.x Maven 3.9.x Docker Compose 2.23.x MongoDB Database Tools 100.9.x 2.2. Generation We generate the project skeleton from ","language":"en","objectID":"49f0bf334f1906ce110e7c468e4d44fa","tags":["EIP","Java","Reactor","MongoDB","Spring Boot","Spring Data","Spring WebFlux","Docker Compose","TestContainers","VisualVM"],"title":"Bulk Update With Spring Data MongoDB Reactive","type":"article","url":"https://www.maoudia.com/blog/bulk-update-with-spring-data-mongodb-reactive/"},{"author":null,"categories":null,"content":"","language":"fr","objectID":"af1f941b6171f8ad8c4635f399406115","tags":null,"title":"Hors ligne","type":"offline","url":"https://www.maoudia.com/fr/offline/"},{"author":null,"categories":null,"content":"","language":"en","objectID":"aed2288437af4cb2dc389424e0c47a4c","tags":null,"title":"Offline","type":"offline","url":"https://www.maoudia.com/offline/"}]